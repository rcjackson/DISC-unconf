## References 
---------------------------- Disha -------------------------------
* [How We Examined Racial Discrimination in Auto Insurance Prices](https://www.propublica.org/article/minority-neighborhoods-higher-car-insurance-premiums-methodology)

* [Turns Out Algorithms Are Racist](https://newrepublic.com/article/144644/turns-algorithms-racist?utm_content=buffer7f3ea&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer)

* [How I'm Fighting Bias in Algorithms (Ted Talk)](http://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms)

* [The Dark Secret at the Heart of AI](https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/)

---------------------------- Bobby -------------------------------
* [AI NOW](https://ainowinstitute.org/)

AI NOW is a research center based out of New York University focusing on the social implications of AI. Their research focuses on studying biases made by AIs that are used to make decisions related to housing, criminal justice, and employment. They also focus on determining the bias in datasets used to train AIs. Finally, they study how to safely integrate AIs into algorithms used by critical infrastructures.

* [AI NOW report](https://assets.contentful.com/8wprhhvnpfc0/1A9c3ZTCZa2KEYM64Wsc2a/8636557c5fb14f2b74b2be64c3ce0c78/_AI_Now_Institute_2017_Report_.pdf)

The AI NOW report summaries several recommendations made by AI NOW in the implementation of AI algorithms for making decisions in hiring, housing, as well as addressing biases in AI research itself. The report also contains a comprehensive literature review summarizing recent work in studying the social implications of AI.

* [Algorithms and bias: What lenders need to know](www.whitecase.com/publications/insight/algorithms-and-bias-what-lenders-need-know)

This article provides a guide on what banks need to consider when using AIs to make decisions regarding lending. It details several main points:
     * AIs learn by using preexisting data that has the desired result already determined through manual means, which is subject to bias.
     * While consumers can view their own credit report and check for its accuracy, there could be data from nontraditional sources which are not available to the consumer to check which lack transarency. This can even go as far as looking at social patterns, such as where a person shops or who they interact with.
     * Recommendations are made that lenders monitor changing regulations and test for potential bias.
     * Any feature in the algorithm should be carefully justified.
     * Algorithms to examine bias in AI algorithms should be developed.
     

* [WHY AI IS STILL WAITING FOR ITS ETHICS TRANSPLANT](https://www.wired.com/story/why-ai-is-still-waiting-for-its-ethics-transplant/)

This is an interview of Kate Crawford, a cofounder of AI Now, conducted by WIRED magazine. She is asked several questions which include  the current state of ethics in AI, how AI developers need to both hire people outside of computer science to better understand social implications, and the state of government funding of ethics research under the Trump adminstration.

---------------------------- Bernie -------------------------------
* Upcoming conference-- 
https://fatconference.org/index.html

* lots of resources--
https://fatconference.org/resources.html 

* [SAP Uses Machine Learning to Find Gender Biased Job Posts](https://www.hrtechnologist.com/news/requisitionjob-posting/sap-uses-machine-learning-to-find-gender-biased-job-posts/)

* [An AI Recruiter Could Find You Your Next Job](https://www.technologyreview.com/the-download/609570/an-ai-recruiter-could-find-you-your-next-job/)

---------------------------- Zairah -------------------------------
* [DeepMind Ethics Research Group - Google](https://deepmind.com/applied/deepmind-ethics-society/research/)

* [Why We Launched DeepMind Ethics & Society](https://deepmind.com/blog/why-we-launched-deepmind-ethics-society/)

* [Responsible Data Science](http://www.responsibledatascience.org/)

* [Bias in software to predict future criminals - biased against blacks](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)
----------------------------------------------------------------------
* [Partnership in AI](https://www.partnershiponai.org)

How do machines learning algorithms learn bias?
https://towardsdatascience.com/how-do-machine-learning-algorithms-learn-bias-555809a1decb

* [Controlling machine learning algorithms and their biases](https://www.mckinsey.com/business-functions/risk/our-insights/controlling-machine-learning-algorithms-and-their-biases)

* [Counterfactual Fairness - Causal models capture social biases and make clear the implicit trade-off between prediction
accuracy and fairness in an unfair world](https://arxiv.org/pdf/1703.06856.pdf)

* [IEEE standards for AI ethics](http://standards.ieee.org/develop/indconn/ec/autonomous_systems.html)

* [Algorithmic accountability](https://techcrunch.com/2017/04/30/algorithmic-accountability/)

* [make algorithms accountable](https://www.nytimes.com/2016/08/01/opinion/make-algorithms-accountable.html)

* [principles for accountable algorithms](https://www.fatml.org/resources/principles-for-accountable-algorithms)

* [Book: What Algorithms Want - Ed Finn](https://mitpress.mit.edu/books/what-algorithms-want)

* [Attacking Discrimination in ML- google research paper](https://research.google.com/bigpicture/attacking-discrimination-in-ml/)

* [Link to White Paper Containing Question Tool](https://cdt.org/issue/privacy-data/digital-decisions/)

* [Equality Opportunity](https://drive.google.com/file/d/0B-wQVEjH9yuhanpyQjUwQS1JOTQ/view)
